{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70d8b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch\n",
    "#packages \n",
    "#Load packages :pytorch, sklearn etc.,\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import copy\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f462a80",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dccbf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the .npz file to train the model \n",
    "def get_training_data(load=False, datafile ='test.npz'):\n",
    "    \n",
    "    if not load:\n",
    "        # This grabs the training data files from the appropriate directory\n",
    "        mypath = './DS440-CAPSTONE/'\n",
    "        training_data_files = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "        \n",
    "        training_t = []  \n",
    "        training_f = []\n",
    "        training_class = []\n",
    "        training_info = []\n",
    "        for f in training_data_files:\n",
    "            data = np.load(mypath+f)\n",
    "            all_time=data['all_time']\n",
    "            all_flux=data['all_flux']\n",
    "            ra = data['ra']\n",
    "            dec = data['dec']\n",
    "            injmu_percentile=data['injmu_percentile']\n",
    "            injduration=data['injduration']\n",
    "            injloc_x=-1 * data['injloc_x']\n",
    "            injloc_y=-1 * data['injloc_y']\n",
    "            injpeak=data['injpeak']\n",
    "            \n",
    "            info = ra,dec,injmu_percentile,injduration,injloc_x,injloc_y,injpeak #injduration, injpeak\n",
    "            for i, t in enumerate(all_time):\n",
    "                f = all_flux[i]\n",
    "                row = np.floor(i/9) - 4\n",
    "                col = i%9 - 4\n",
    "                if np.all(np.isnan(f)):\n",
    "                    continue\n",
    "                if np.sqrt((row - injloc_x)**2 + (col-injloc_y)**2)<=2:\n",
    "                    training_t.append(t)\n",
    "                    training_f.append(f)\n",
    "                    training_class.append(1)\n",
    "                    training_info.append(info)\n",
    "                    \n",
    "                elif np.sqrt((row - injloc_x)**2 + (col-injloc_y)**2)>5:\n",
    "                    training_t.append(t)\n",
    "                    training_f.append(f)\n",
    "                    training_class.append(0)\n",
    "                    training_info.append(info)\n",
    "        np.savez(datafile,training_t = training_t, training_f = training_f,\n",
    "                training_class = training_class, training_info = training_info)\n",
    "        return training_t, training_f,training_class,training_info\n",
    "    else:\n",
    "        data = np.load(datafile, allow_pickle=True)\n",
    "        training_t = data['training_t']         # needs to be padded and then shuffled\n",
    "        training_f = data['training_f']         \n",
    "        training_class = data['training_class']  \n",
    "        training_info = data['training_info']   \n",
    "        return training_t, training_f,training_class,training_info\n",
    "training_t, training_f,training_class,training_info = get_training_data(load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b83232f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding the arrays to match the max size\n",
    "longest_len = 3658\n",
    "for i in np.arange(len(training_t)):\n",
    "    mylen = len(training_t[i])\n",
    "    if mylen>longest_len:\n",
    "        longest_len = mylen\n",
    "new_training_t = np.zeros((len(training_t),longest_len))\n",
    "new_training_f = np.zeros((len(training_t),longest_len))\n",
    "for i in np.arange(len(training_t)):\n",
    "    nl = len(training_t[i])\n",
    "    before_N=int(longest_len/2-(nl/2))\n",
    "    new_training_t[i,before_N:nl+before_N] = training_t[i]   # Data to be used\n",
    "    new_training_f[i,before_N:nl+before_N] = training_f[i]   # Data to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc7fe636-9e81-41b2-ace5-fc231f5d141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_nt_f = new_training_f.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07fb2923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(float_nt_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0caf7ac-3204-4804-9fe9-61729a57d0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_nt_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e26bd12-274c-4e0b-8dab-b3f35f2c0db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12116, 3658)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_training_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acc47e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12116,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e210a181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# introducing balanced dataset \n",
    "\n",
    "#new set with 50/50 SNe\n",
    "count_arr = np.bincount(training_class)\n",
    "count1 = count_arr[1]\n",
    "count0 = count_arr[0]\n",
    "\n",
    "#get index of 0's, 1's-> np.where \n",
    "#np.random.choice?(replace= False ) returns a random sample of zeroes. \n",
    "\n",
    "zero=np.where(training_class==0)[0]  # the [0] just means the first \"element\" in this case array is selected. np.where makes a matrix of size nx2 for some reason \n",
    "one = np.where(training_class==1)[0] \n",
    "#get the indexes\n",
    "train_c0 = np.random.choice(zero, size=2383, replace=False, p=None)\n",
    "train_f0 = new_training_f[train_c0]\n",
    "train_c00= training_class[train_c0]\n",
    "\n",
    "train_f1 = new_training_f[one]\n",
    "train_c11 = training_class[one]\n",
    "\n",
    "train_c_all = np.append(train_c00,train_c11)\n",
    "train_f_all = np.vstack((train_f0,train_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d273cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01ed611e-31f2-435b-9209-405fbbe39d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self, train_c_all, train_f_all, transform=None, target_transform=None):   #train_c_all,train_f_all -                                                                                    \n",
    "        self.labels = train_c_all                                                         #from balanced set \n",
    "        self.data = train_f_all\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #img_path = os.path.join(self.data, self.labels.iloc[idx, 0])\n",
    "        curve = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            curve = self.transform(curve)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return curve, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7a159b7-2c9e-4754-a145-4ef551eda926",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = CustomDataset(training_class, float_nt_f, transform=None, target_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89bc90d3-72e6-4c33-86ab-bc989fe478c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.9\n",
    "TEST_RATIO = 0.66\n",
    "\n",
    "n_train_examples = int(len(train) * TEST_RATIO)\n",
    "n_test_examples = len(train) - n_train_examples\n",
    "n_train_examples = int(n_train_examples * VALID_RATIO)\n",
    "n_valid_examples = len(train) - n_test_examples - n_train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cb3ab38-280c-4757-a983-1a4758422f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, valid_data = data.random_split(train, [n_train_examples, n_test_examples, n_valid_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98fc496a-f821-432d-8469-797d287ec922",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator = data.DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_iterator = data.DataLoader(valid_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_iterator = data.DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182dbe58-5824-4f99-8a25-828230d63888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "544a9108-de41-44fe-813c-d6d2e5be951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_fc = nn.Linear(input_dim, 1400)\n",
    "        self.hidden_fc1 = nn.Linear(1400, 530)\n",
    "        self.hidden_fc2 = nn.Linear(530, 200)\n",
    "        self.hidden_fc3 = nn.Linear(200, 80)\n",
    "        self.output_fc = nn.Linear(80, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x = [batch size, height, width]\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        x = x.view(batch_size, -1)\n",
    "\n",
    "        # x = [batch size, height * width]\n",
    "\n",
    "        h_1 = F.relu(self.input_fc(x))\n",
    "\n",
    "        # h_1 = [batch size, 1400]\n",
    "\n",
    "        h_2 = F.relu(self.hidden_fc1(h_1))\n",
    "\n",
    "        # h_2 = [batch size, 530]\n",
    "        \n",
    "        h_3 = F.relu(self.hidden_fc2(h_2))\n",
    "\n",
    "        # h_3 = [batch size, 200]\n",
    "        \n",
    "        h_4 = F.relu(self.hidden_fc3(h_3))\n",
    "\n",
    "        # h_4 = [batch size, 80]\n",
    "\n",
    "        y_pred = self.output_fc(h_4)\n",
    "\n",
    "        # y_pred = [batch size, output dim]\n",
    "\n",
    "        return y_pred, h_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e045d9-aa16-4623-bf36-96ca5942e29d",
   "metadata": {},
   "source": [
    "define our model by creating an instance of it and setting the correct input and output dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12d6a268-497b-4362-950d-26cd4b931048",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 3658\n",
    "OUTPUT_DIM = 2\n",
    "\n",
    "model = MLP(INPUT_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81952984-46f0-4b22-bbec-b95c432e6bb0",
   "metadata": {},
   "source": [
    "calculate the number of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0bfc3f5-e7ee-4d23-b2f1-834125f25f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bca8750-ab78-4b4a-8039-11c6a7f4c6b1",
   "metadata": {},
   "source": [
    "The first layer has 3658 neurons connected to 1400 neurons, so 3658*1400 weighted connections plus 1400 bias terms.\n",
    "\n",
    "The second layer has 1400 neurons connected to 530 neurons, 1400*530 weighted connections plus 530 bias terms.\n",
    "\n",
    "The third layer has 530 neurons connected to 200 neurons, 530*200 weighted connections plus 200 bias terms.\n",
    "\n",
    "The fourth layer has 200 neurons connected to 80 neurons, 200*80 weighted connections plus 80 bias terms.\n",
    "\n",
    "The fifth layer has 80 neurons connected to 2 neurons, 80*2 weighted connections plus 2 bias terms.\n",
    "\n",
    "$$3658 \\cdot 1400 + 1400 + 1400 \\cdot 530 + 530 + 530 \\cdot 200 + 200 + 200 \\cdot 80 + 80 + 80 \\cdot 2 + 2 = 5,987,572 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63d259c6-a378-4aa2-a8eb-0716784043cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 5,987,572 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cd5c6d0-dd38-4bd5-af6f-a497eee62197",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16f4f196-0463-4fd2-a9fb-cb6d01fd6124",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0ba512e-83a8-40e6-9e1d-6a279fda9d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc8a6f3d-8501-42bb-964c-909b2757101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14b0b449-acaa-4cbd-8aa4-19851bb4ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim=True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3a611fe-69a7-4383-b54a-56ba5b942aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred, _ = model(x.float())\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4551b11-d59f-43d6-93a3-927ce116ec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=False):\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred, _ = model(x.float())\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afb090a9-8c92-47c7-96c8-76a7ec70bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d37cd409-4a3a-466c-b646-5a07af3a02fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3fdc36be53445f8306c175646fac3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.621 | Train Acc: 87.99%\n",
      "\t Val. Loss: 0.653 |  Val. Acc: 93.27%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.213 | Train Acc: 94.01%\n",
      "\t Val. Loss: 0.139 |  Val. Acc: 97.36%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.122 | Train Acc: 97.01%\n",
      "\t Val. Loss: 0.066 |  Val. Acc: 97.60%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.205 | Train Acc: 96.17%\n",
      "\t Val. Loss: 0.070 |  Val. Acc: 98.68%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.084 | Train Acc: 97.76%\n",
      "\t Val. Loss: 0.059 |  Val. Acc: 99.16%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.080 | Train Acc: 98.40%\n",
      "\t Val. Loss: 0.082 |  Val. Acc: 98.32%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.046 | Train Acc: 98.73%\n",
      "\t Val. Loss: 0.011 |  Val. Acc: 99.76%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.844 | Train Acc: 93.32%\n",
      "\t Val. Loss: 0.069 |  Val. Acc: 98.68%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.870 | Train Acc: 89.35%\n",
      "\t Val. Loss: 0.307 |  Val. Acc: 91.23%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.197 | Train Acc: 95.68%\n",
      "\t Val. Loss: 0.141 |  Val. Acc: 94.95%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in trange(EPOCHS):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7c732a4-55f5-4710-9470-2cd2bed22d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##rename the .pt file\n",
    "\n",
    "#model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb053a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.232 | Test Acc: 95.04%\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfed978f",
   "metadata": {},
   "source": [
    "Examining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0700760-5c9b-43e4-83d3-45f762f91b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, iterator, device):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            y_pred, _ = model(x.float())\n",
    "\n",
    "            y_prob = F.softmax(y_pred, dim=-1)\n",
    "\n",
    "            images.append(x.cpu())\n",
    "            labels.append(y.cpu())\n",
    "            probs.append(y_prob.cpu())\n",
    "\n",
    "    images = torch.cat(images, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    probs = torch.cat(probs, dim=0)\n",
    "\n",
    "    return images, labels, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "671a937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, probs = get_predictions(model, test_iterator, device)\n",
    "\n",
    "pred_labels = torch.argmax(probs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "424829e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(labels, pred_labels):\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    cm = metrics.confusion_matrix(labels, pred_labels)\n",
    "    cm = metrics.ConfusionMatrixDisplay(cm, display_labels=range(10))\n",
    "    cm.plot(values_format='d', cmap='Blues', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f290e1dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (2), usually from a call to set_ticks, does not match the number of ticklabels (10).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36mplot_confusion_matrix\u001b[1;34m(labels, pred_labels)\u001b[0m\n\u001b[0;32m      5\u001b[0m cm \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mconfusion_matrix(labels, pred_labels)\n\u001b[0;32m      6\u001b[0m cm \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mConfusionMatrixDisplay(cm, display_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m----> 7\u001b[0m \u001b[43mcm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43md\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBlues\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43max\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py:172\u001b[0m, in \u001b[0;36mConfusionMatrixDisplay.plot\u001b[1;34m(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar, im_kw)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m colorbar:\n\u001b[0;32m    171\u001b[0m     fig\u001b[38;5;241m.\u001b[39mcolorbar(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim_, ax\u001b[38;5;241m=\u001b[39max)\n\u001b[1;32m--> 172\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxticks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43myticks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43myticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mylabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrue label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPredicted label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylim((n_classes \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m))\n\u001b[0;32m    182\u001b[0m plt\u001b[38;5;241m.\u001b[39msetp(ax\u001b[38;5;241m.\u001b[39mget_xticklabels(), rotation\u001b[38;5;241m=\u001b[39mxticks_rotation)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py:116\u001b[0m, in \u001b[0;36mArtist.__init_subclass__.<locals>.<lambda>\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_autogenerated_signature\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# Don't overwrite cls.set if the subclass or one of its parents\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# has defined a set method set itself.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# If there was no explicit definition, cls.set is inherited from\u001b[39;00m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# the hierarchy of auto-generated set methods, which hold the\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# flag _autogenerated_signature.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Artist\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py:1164\u001b[0m, in \u001b[0;36mArtist.set\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1160\u001b[0m     \u001b[38;5;66;03m# docstring and signature are auto-generated via\u001b[39;00m\n\u001b[0;32m   1161\u001b[0m     \u001b[38;5;66;03m# Artist._update_set_signature_and_docstring() at the end of the\u001b[39;00m\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;66;03m# module.\u001b[39;00m\n\u001b[0;32m   1163\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py:1066\u001b[0m, in \u001b[0;36mArtist.update\u001b[1;34m(self, props)\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(func):\n\u001b[0;32m   1064\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1065\u001b[0m                                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas no property \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1066\u001b[0m             ret\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[0;32m   1068\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpchanged()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:75\u001b[0m, in \u001b[0;36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_method(\u001b[38;5;28mself\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py:1798\u001b[0m, in \u001b[0;36mAxis._set_ticklabels\u001b[1;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fontdict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1797\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(fontdict)\n\u001b[1;32m-> 1798\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_ticklabels(labels, minor\u001b[38;5;241m=\u001b[39mminor, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py:1720\u001b[0m, in \u001b[0;36mAxis.set_ticklabels\u001b[1;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(locator, mticker\u001b[38;5;241m.\u001b[39mFixedLocator):\n\u001b[0;32m   1717\u001b[0m     \u001b[38;5;66;03m# Passing [] as a list of ticklabels is often used as a way to\u001b[39;00m\n\u001b[0;32m   1718\u001b[0m     \u001b[38;5;66;03m# remove all tick labels, so only error for > 0 ticklabels\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(ticklabels) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ticklabels) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1720\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1721\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of FixedLocator locations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1722\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), usually from a call to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1723\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m set_ticks, does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1724\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the number of ticklabels (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ticklabels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1725\u001b[0m     tickd \u001b[38;5;241m=\u001b[39m {loc: lab \u001b[38;5;28;01mfor\u001b[39;00m loc, lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs, ticklabels)}\n\u001b[0;32m   1726\u001b[0m     func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_with_dict, tickd)\n",
      "\u001b[1;31mValueError\u001b[0m: The number of FixedLocator locations (2), usually from a call to set_ticks, does not match the number of ticklabels (10)."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b20e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conclusion kinda did worse than before?\n",
    "# the data being already imbalanced \n",
    "# next to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36525fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in a small test set with real SNe to see how the model actually performs.\n",
    "# Some actual testing on SNe = test_sn.npz\n",
    "#read in the data \n",
    "def get_testing_data(load=False, datafile ='test_sn (1).npz'):\n",
    "    \n",
    "    if not load:\n",
    "        # This grabs the training data files from the appropriate directory\n",
    "        mypath = './pipelinefile_/'\n",
    "        training_data_files = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "        \n",
    "        test_t = []  \n",
    "        test_f = []\n",
    "        test_class = []\n",
    "        test_info = []\n",
    "        for f in training_data_files:\n",
    "            data = np.load(mypath+f)\n",
    "            all_time=data['all_time']\n",
    "            all_flux=data['all_flux']\n",
    "            ra = data['ra']\n",
    "            dec = data['dec']\n",
    "            injmu_percentile=data['injmu_percentile']\n",
    "            injduration=data['injduration']\n",
    "            injloc_x=-1 * data['injloc_x']\n",
    "            injloc_y=-1 * data['injloc_y']\n",
    "            injpeak=data['injpeak']\n",
    "            \n",
    "            info = ra,dec,injmu_percentile,injduration,injloc_x,injloc_y,injpeak #injduration, injpeak\n",
    "            for i, t in enumerate(all_time):\n",
    "                f = all_flux[i]\n",
    "                row = np.floor(i/9) - 4\n",
    "                col = i%9 - 4\n",
    "                if np.all(np.isnan(f)):\n",
    "                    continue\n",
    "                if np.sqrt((row - injloc_x)**2 + (col-injloc_y)**2)<=2:\n",
    "                    test_t.append(t)\n",
    "                    test_f.append(f)\n",
    "                    test_class.append(1)\n",
    "                    test_info.append(info)\n",
    "                    \n",
    "                elif np.sqrt((row - injloc_x)**2 + (col-injloc_y)**2)>5:\n",
    "                    test_t.append(t)\n",
    "                    test_f.append(f)\n",
    "                    test_class.append(0)\n",
    "                    test_info.append(info)\n",
    "        np.savez(datafile,testg_t = test_t, test_f = test_f,\n",
    "                test_class = test_class, test_info = test_info)\n",
    "        return test_t, test_f,test_class,test_info\n",
    "    else:\n",
    "        data = np.load(datafile, allow_pickle=True)\n",
    "        test_t = data['training_t']         # needs to be padded and then shuffled\n",
    "        test_f = data['training_f']         \n",
    "        test_class = data['training_class']  \n",
    "        test_info = data['training_info']   \n",
    "        return test_t, test_f,test_class,test_info\n",
    "test_t, test_f,test_class,test_info = get_testing_data(load=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c680b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding padding to the curves\n",
    "Xtest = np.array(test_f)\n",
    "Ytest = np.array(test_class)\n",
    "\n",
    "longest_len = 3658\n",
    "for i in np.arange(len(Xtest)): \n",
    "    mylen = len(Xtest[i]) \n",
    "    if mylen>longest_len:\n",
    "        longest_len = mylen\n",
    "new_f = np.zeros((len(Xtest),longest_len)) \n",
    "for i in np.arange(len(Xtest)): \n",
    "    nl = len(Xtest[i]) \n",
    "    before_N=int(longest_len/2-(nl/2))\n",
    "    new_f[i,before_N:nl+before_N] = Xtest[i]  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the fluxes!! Imp step \n",
    "\n",
    "xtest = scaler.fit_transform(new_f.T).T  # might not work here just yet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
